{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_video_path = './2023_4.mp4' # 更改為要預測的影片路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNLightning(pl.LightningModule):\n",
    "    def __init__(self, num_classes=4, learning_rate=0.0001):\n",
    "        super(SimpleCNNLightning, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.fc1 = nn.Linear(512 * 8 * 8, 1024)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def predict_cnn(image):\n",
    "    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = cnn_model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_path = \"./checkpoints/CNN5_model.ckpt\"\n",
    "cnn_model = SimpleCNNLightning.load_from_checkpoint(cnn_path)\n",
    "cnn_model = cnn_model.to(device)\n",
    "cnn_model.eval() \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#%%\n",
    "yolo_path = \"./checkpoints/best.pt\"\n",
    "model = YOLO(yolo_path)\n",
    "cap = cv2.VideoCapture(demo_video_path) # Open the video file\n",
    "num = 0 # count the number of frames\n",
    "while True:\n",
    "    success, frame = cap.read() # Read the frame\n",
    "    if success:\n",
    "        num += 1\n",
    "        if frame.shape[0] != 480 or frame.shape[1] != 640:\n",
    "            frame = cv2.resize(frame, (640, 480))\n",
    "        results = model.predict(frame, conf=0.25) # YOLOv8 Track the object in the frame\n",
    "        if results[0].boxes.shape[0] > 0: # If the object is detected\n",
    "            for i, box in enumerate(results[0].boxes.xyxy.cpu().numpy().astype(int)): # Draw the bounding box of the object\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                cropped_img = frame[y_min:y_max, x_min:x_max]\n",
    "                cropped_img = cv2.resize(cropped_img, (128, 128))\n",
    "                pose_pred = predict_cnn(cropped_img)\n",
    "                x_center = (x_min + x_max) / 2 / frame.shape[1]\n",
    "                y_center = (y_min + y_max) / 2 / frame.shape[0]\n",
    "                bbox_width = (x_max - x_min) / frame.shape[1]\n",
    "                bbox_height = (y_max - y_min) / frame.shape[0]\n",
    "                                \n",
    "                match pose_pred:\n",
    "                    case 0:\n",
    "                        id_char = 'bending'\n",
    "                    case 1:\n",
    "                        id_char = 'stand'\n",
    "                    case 2:\n",
    "                        id_char = 'lie'\n",
    "                    case 3:\n",
    "                        id_char = 'fall'\n",
    "                color = {\n",
    "                        0: (0, 0, 255),   # Red for bending\n",
    "                        1: (0, 255, 0),   # Green for stand\n",
    "                        2: (255, 0, 0),   # Blue for lie\n",
    "                        3: (0, 255, 255)  # Yellow for fall\n",
    "                    }[pose_pred]\n",
    "                    \n",
    "                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "                cv2.putText(frame, f\"{id_char}\", (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
